{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/szagoruyko/pytorchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.3.1\n",
      "tensorboardX: 2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorboardX\n",
    "print(\"torch:\",torch.__version__)\n",
    "print(\"tensorboardX:\",tensorboardX.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "\n",
    "best_acc1 = 0\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if args.gpu is not None:\n",
    "                images = images.cuda(args.gpu, non_blocking=True)\n",
    "            target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, lr):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alexnet',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'googlenet',\n",
       " 'inception_v3',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet_v2',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext50_32x4d',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"~/image_net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~/image_net'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  val\r\n"
     ]
    }
   ],
   "source": [
    "!ls {data_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch='resnet18'\n",
    "lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'resnet18'\n"
     ]
    }
   ],
   "source": [
    "global best_acc1\n",
    "batch_size = 4\n",
    "# create model\n",
    "# if args.pretrained:\n",
    "#     print(\"=> using pre-trained model '{}'\".format(args.arch))\n",
    "#     model = models.__dict__[args.arch](pretrained=True)\n",
    "# else:\n",
    "print(\"=> creating model '{}'\".format(arch))\n",
    "model = models.__dict__[arch]()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr,\n",
    "                            momentum=0.9,\n",
    "                            weight_decay=1e-4)\n",
    "\n",
    "\n",
    "# Data loading code\n",
    "traindir = os.path.join(data_path, 'train')\n",
    "valdir = os.path.join(data_path, 'val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size,\n",
    "    num_workers=2)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=batch_size, shuffle=False,\n",
    "    num_workers=2)\n",
    "\n",
    "# if args.evaluate:\n",
    "#     validate(val_loader, model, criterion, args)\n",
    "# else:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelinspector.inspector import Inspector\n",
    "inspector = Inspector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing graph (0, 0)..\n",
      "Epoch: [0][   0/4852]\tTime  0.580 ( 0.580)\tData  0.103 ( 0.103)\tLoss 7.2120e+00 (7.2120e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Epoch: [0][   1/4852]\tTime  0.018 ( 0.299)\tData  0.001 ( 0.052)\tLoss 0.0000e+00 (3.6060e+00)\tAcc@1 100.00 ( 50.00)\tAcc@5 100.00 ( 50.00)\n",
      "Epoch: [0][   2/4852]\tTime  0.084 ( 0.227)\tData  0.002 ( 0.035)\tLoss 0.0000e+00 (2.4040e+00)\tAcc@1 100.00 ( 66.67)\tAcc@5 100.00 ( 66.67)\n",
      "Epoch: [0][   3/4852]\tTime  0.018 ( 0.175)\tData  0.001 ( 0.027)\tLoss 0.0000e+00 (1.8030e+00)\tAcc@1 100.00 ( 75.00)\tAcc@5 100.00 ( 75.00)\n",
      "Epoch: [0][   4/4852]\tTime  0.084 ( 0.157)\tData  0.002 ( 0.022)\tLoss 0.0000e+00 (1.4424e+00)\tAcc@1 100.00 ( 80.00)\tAcc@5 100.00 ( 80.00)\n",
      "Epoch: [0][   5/4852]\tTime  0.017 ( 0.134)\tData  0.002 ( 0.018)\tLoss 0.0000e+00 (1.2020e+00)\tAcc@1 100.00 ( 83.33)\tAcc@5 100.00 ( 83.33)\n",
      "Epoch: [0][   6/4852]\tTime  0.084 ( 0.126)\tData  0.003 ( 0.016)\tLoss 1.1482e+02 (1.7433e+01)\tAcc@1  25.00 ( 75.00)\tAcc@5  25.00 ( 75.00)\n",
      "Epoch: [0][   7/4852]\tTime  0.019 ( 0.113)\tData  0.002 ( 0.014)\tLoss 1.0313e+02 (2.8145e+01)\tAcc@1   0.00 ( 65.62)\tAcc@5 100.00 ( 78.12)\n",
      "Epoch: [0][   8/4852]\tTime  0.083 ( 0.110)\tData  0.002 ( 0.013)\tLoss 2.0923e+01 (2.7343e+01)\tAcc@1   0.00 ( 58.33)\tAcc@5 100.00 ( 80.56)\n",
      "Epoch: [0][   9/4852]\tTime  0.017 ( 0.100)\tData  0.002 ( 0.012)\tLoss 4.6730e-05 (2.4608e+01)\tAcc@1 100.00 ( 62.50)\tAcc@5 100.00 ( 82.50)\n",
      "Epoch: [0][  10/4852]\tTime  0.084 ( 0.099)\tData  0.003 ( 0.011)\tLoss 0.0000e+00 (2.2371e+01)\tAcc@1 100.00 ( 65.91)\tAcc@5 100.00 ( 84.09)\n",
      "Epoch: [0][  11/4852]\tTime  0.019 ( 0.092)\tData  0.002 ( 0.010)\tLoss 0.0000e+00 (2.0507e+01)\tAcc@1 100.00 ( 68.75)\tAcc@5 100.00 ( 85.42)\n",
      "Epoch: [0][  12/4852]\tTime  0.136 ( 0.096)\tData  0.002 ( 0.010)\tLoss 0.0000e+00 (1.8929e+01)\tAcc@1 100.00 ( 71.15)\tAcc@5 100.00 ( 86.54)\n",
      "Epoch: [0][  13/4852]\tTime  0.017 ( 0.090)\tData  0.002 ( 0.009)\tLoss 2.3249e+01 (1.9238e+01)\tAcc@1  50.00 ( 69.64)\tAcc@5  50.00 ( 83.93)\n",
      "Epoch: [0][  14/4852]\tTime  0.084 ( 0.090)\tData  0.003 ( 0.009)\tLoss 6.6670e+01 (2.2400e+01)\tAcc@1   0.00 ( 65.00)\tAcc@5 100.00 ( 85.00)\n",
      "Epoch: [0][  15/4852]\tTime  0.019 ( 0.085)\tData  0.002 ( 0.008)\tLoss 5.0336e+01 (2.4146e+01)\tAcc@1   0.00 ( 60.94)\tAcc@5 100.00 ( 85.94)\n",
      "Epoch: [0][  16/4852]\tTime  0.084 ( 0.085)\tData  0.002 ( 0.008)\tLoss 3.4130e+01 (2.4733e+01)\tAcc@1   0.00 ( 57.35)\tAcc@5 100.00 ( 86.76)\n",
      "Epoch: [0][  17/4852]\tTime  0.017 ( 0.081)\tData  0.002 ( 0.008)\tLoss 1.4230e+01 (2.4150e+01)\tAcc@1   0.00 ( 54.17)\tAcc@5 100.00 ( 87.50)\n",
      "Epoch: [0][  18/4852]\tTime  0.083 ( 0.081)\tData  0.003 ( 0.007)\tLoss 8.9046e+00 (2.3348e+01)\tAcc@1  50.00 ( 53.95)\tAcc@5 100.00 ( 88.16)\n",
      "Epoch: [0][  19/4852]\tTime  0.018 ( 0.078)\tData  0.002 ( 0.007)\tLoss 7.0461e+00 (2.2533e+01)\tAcc@1  25.00 ( 52.50)\tAcc@5  50.00 ( 86.25)\n",
      "Epoch: [0][  20/4852]\tTime  0.083 ( 0.078)\tData  0.002 ( 0.007)\tLoss 6.9964e+00 (2.1793e+01)\tAcc@1   0.00 ( 50.00)\tAcc@5  75.00 ( 85.71)\n",
      "Epoch: [0][  21/4852]\tTime  0.018 ( 0.076)\tData  0.002 ( 0.007)\tLoss 6.7345e+00 (2.1108e+01)\tAcc@1   0.00 ( 47.73)\tAcc@5 100.00 ( 86.36)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "        adjust_learning_rate(optimizer, epoch, lr)\n",
    "\n",
    "        # train for one epoch\n",
    "#         train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "#         for it in sdf:\n",
    "        batch_time = AverageMeter('Time', ':6.3f')\n",
    "        data_time = AverageMeter('Data', ':6.3f')\n",
    "        losses = AverageMeter('Loss', ':.4e')\n",
    "        top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "        top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "        progress = ProgressMeter(\n",
    "            len(train_loader),\n",
    "            [batch_time, data_time, losses, top1, top5],\n",
    "            prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "        # switch to train mode\n",
    "        model.train()\n",
    "\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(train_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # compute gradient and do SGD step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            if i % 2 == 0:\n",
    "                inspector.log(epoch=epoch,\n",
    "                          itr=i, \n",
    "                          model=model,\n",
    "                          input_dict={'input.1':images},\n",
    "                          output_dict={'output.1':output},\n",
    "                          loss_dict={'loss':loss},\n",
    "                          label_dict={'class_label':target})\n",
    "\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % 1 == 0:\n",
    "                progress.display(i)\n",
    "            if i > 20:\n",
    "                break\n",
    "\n",
    "        # evaluate on validation set\n",
    "        #acc1 = validate(val_loader, model, criterion, args)\n",
    "\n",
    "        # remember best acc@1 and save checkpoint\n",
    "        #is_best = acc1 > best_acc1\n",
    "        #best_acc1 = max(acc1, best_acc1)\n",
    "        \n",
    "# ON CPU\n",
    "# Computing graph (0, 0)..\n",
    "# Computing graph (0, 0)..\n",
    "# Epoch: [0][   0/4852]\tTime  1.260 ( 1.260)\tData  0.072 ( 0.072)\tLoss 6.6802e+00 (6.6802e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
    "# Epoch: [0][ 200/4852]\tTime  0.593 ( 0.675)\tData  0.002 ( 0.002)\tLoss 7.8017e+00 (9.1996e+00)\tAcc@1   0.00 (  5.10)\tAcc@5   0.00 ( 19.78)\n",
    "# Epoch: [1][   0/4852]\tTime  0.864 ( 0.864)\tData  0.155 ( 0.155)\tLoss 9.2710e+00 (9.2710e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
    "# Epoch: [1][ 200/4852]\tTime  0.706 ( 0.599)\tData  0.002 ( 0.002)\tLoss 6.3036e+00 (5.9345e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspector.log(epoch=epoch,\n",
    "#           itr=i, \n",
    "#           model=model,\n",
    "#           input_dict={'input.1':images},\n",
    "#           output_dict={'output.1':output},\n",
    "#           loss_dict={'loss':loss},\n",
    "#           label_dict={'class_label':target})\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brandyn/anaconda3/envs/rlevo/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3506: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "/home/brandyn/anaconda3/envs/rlevo/lib/python3.7/site-packages/numpy/core/_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/brandyn/anaconda3/envs/rlevo/lib/python3.7/site-packages/numpy/core/_methods.py:209: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/brandyn/anaconda3/envs/rlevo/lib/python3.7/site-packages/scipy/stats/stats.py:1121: RuntimeWarning: invalid value encountered in true_divide\n",
      "  lambda m2, m3: m3 / m2**1.5,\n"
     ]
    }
   ],
   "source": [
    "inspector.compute_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inspector.state_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspector.graph_data[(0, 21)].components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspector.graph_data[(0, 21)].nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelinspector.inspector import build_state_images, stats_suffix, DataGroupType_BUFFER, DataGroupType_INPUT, DataGroupType_LABEL, DataGroupType_OUTPUT, DataGroupType_PARAM, DataGroupType_LOSS\n",
    "from modelinspector.vis_utils import tensor_to_image, tensor_to_dist, fig2img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TROUBLESHOOTING\n",
    "# from modelinspector.modelgraph import get_onnx_model_from_torch, ModelGraph\n",
    "\n",
    "# onex_model = get_onnx_model_from_torch(model, images)\n",
    "\n",
    "# # inspector.graph_data[(0,0)].edges\n",
    "\n",
    "# x = onex_model.graph.input[0].type.tensor_type.shape.dim\n",
    "\n",
    "\n",
    "# for xx in x:\n",
    "#     print(xx)\n",
    "\n",
    "# onex_graph = onex_model.graph\n",
    "\n",
    "# onex_graph.input\n",
    "\n",
    "# onex_graph.node[68]\n",
    "\n",
    "# onex_graph.output\n",
    "\n",
    "# onex_graph.output\n",
    "\n",
    "# onex_graph.sparse_initializer\n",
    "\n",
    "# onex_graph.quantization_annotation\n",
    "\n",
    "# for init in onex_graph.initializer:\n",
    "#     print(init.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for node in onex_model.graph.node:\n",
    "#     print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_types = ['image','dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def build_state_images(\n",
    "                state,\n",
    "                state_stats=None):\n",
    "    state_image_data = {}\n",
    "\n",
    "    for group_name, group_data in state['data'].items():\n",
    "        image_data = {}\n",
    "        if group_data['data_group_type'] == DataGroupType_PARAM:    \n",
    "            #param\n",
    "            param_stats = group_data['value']['tensor{}'.format(stats_suffix)] #TODO, use global stats\n",
    "            image_data[\"tensor__image\"] = tensor_to_image(\n",
    "                val = group_data['value']['tensor'],\n",
    "                vstats = param_stats)\n",
    "            #grad\n",
    "            grad_stats = group_data['value']['grad{}'.format(stats_suffix)] #TODO, use global stats\n",
    "            image_data[\"grad__image\"] = tensor_to_image(\n",
    "                val = group_data['value']['grad'],\n",
    "                vstats = grad_stats)\n",
    "        elif group_data['data_group_type'] == DataGroupType_INPUT:\n",
    "            image_data[\"tensor__image\"] = tensor_to_image(\n",
    "                val = group_data['value']['tensor'],\n",
    "                vstats = None, \n",
    "                use_color_for_3channel_data=True)    \n",
    "        elif group_data['data_group_type'] == DataGroupType_BUFFER:\n",
    "            image_data[\"tensor__image\"] = tensor_to_image(\n",
    "                val = group_data['value']['tensor'],\n",
    "                vstats = None, \n",
    "                use_color_for_3channel_data=False)\n",
    "        elif group_data['data_group_type'] == DataGroupType_OUTPUT:\n",
    "            image_data[\"tensor__image\"] = tensor_to_image(\n",
    "                val = group_data['value']['tensor'],\n",
    "                vstats = None, \n",
    "                use_color_for_3channel_data=False)\n",
    "        elif group_data['data_group_type'] == DataGroupType_LOSS:\n",
    "            image_data[\"tensor__image\"] = tensor_to_image(\n",
    "                val = group_data['value']['tensor'],\n",
    "                vstats = None, \n",
    "                use_color_for_3channel_data=False)\n",
    "        state_image_data[group_name] = image_data\n",
    "        \n",
    "    return state_image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# def build_state_figs(\n",
    "#                 state,\n",
    "#                 state_stats=None):\n",
    "#     state_fig_data = {}\n",
    "\n",
    "#     for group_name, group_data in state['data'].items():\n",
    "#         print(\"Processing {}\".format(group_name))\n",
    "#         image_data = {}\n",
    "#         if group_data['data_group_type'] == DataGroupType_PARAM:    \n",
    "#             #param\n",
    "#             param_stats = group_data['value']['tensor{}'.format(stats_suffix)] \n",
    "#             image_data[\"tensor__distfig\"] = tensor_to_dist(\n",
    "#                 val = group_data['value']['tensor'],\n",
    "#                 vstats = param_stats)\n",
    "#             #grad\n",
    "#             grad_stats = group_data['value']['grad{}'.format(stats_suffix)]\n",
    "#             image_data[\"grad__distfig\"] = tensor_to_dist(\n",
    "#                 val = group_data['value']['grad'],\n",
    "#                 vstats = grad_stats)\n",
    "#         else:\n",
    "#             stats = group_data['value']['tensor{}'.format(stats_suffix)] \n",
    "#             image_data[\"tensor__distfig\"] = tensor_to_dist(\n",
    "#                 val = group_data['value']['tensor'],\n",
    "#                 vstats = stats)\n",
    "#         state_fig_data[group_name] = image_data\n",
    "        \n",
    "#     return state_fig_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save_images(state_image_data,output_path): #TODO: use these):\n",
    "    filenames = {}\n",
    "    os.makedirs(output_path,exist_ok=True)\n",
    "    for group_name, image_data in state_image_data.items():\n",
    "        filename_list = []\n",
    "        for img_name,img in image_data.items():\n",
    "            filename = \"{}_{}.jpg\".format(group_name,img_name)\n",
    "            filename_list.append({'filename':filename,'size': img.size})\n",
    "            img.save(os.path.join(output_path,filename))\n",
    "        state_image_data[group_name] = image_data\n",
    "        filenames[group_name] = filename_list\n",
    "        \n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /tmp/modelinspector/state_images/0_2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cyto_graph_file(graph):\n",
    "    nodes = []\n",
    "    edges = []\n",
    "    only_one_input = []\n",
    "    for nid,node in graph.nodes.items():\n",
    "        nodes.append({\"data\":{\"id\":nid,'label':node['op_type'],'component_ids':node['component_ids']}})\n",
    "\n",
    "    for eid,edge in graph.edges.items():\n",
    "        edges.append({'data':{'id':eid,\"source\":edge['source_id'],'target':edge['target_id']}})\n",
    "        \n",
    "    return {'nodes':nodes,'edges':edges}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib agg\n",
    "import matplotlib.pyplot as plt\n",
    "#datasets = [('name',{'xmin':-10,'xmax':30},dd) for x in range(0,5)]\n",
    "def build_figs(datasets,n_bins=40):\n",
    "    fig, axs = plt.subplots(len(datasets), 1, tight_layout=True,figsize=(8,8));\n",
    "\n",
    "    for i,(name,stats,data) in enumerate(datasets):\n",
    "        if len(datasets)==1:\n",
    "            ax = axs\n",
    "        else:\n",
    "            ax = axs[i]\n",
    "\n",
    "        if data.ndim >1:\n",
    "            data = data.ravel()\n",
    "\n",
    "        bins = min(int(data.size/10)+2, n_bins)\n",
    "\n",
    "        ax.hist(data, bins=bins,range=(stats['min'],stats['max']))\n",
    "        ax.set_title(name)\n",
    "\n",
    "    figimg = fig2img(fig).convert(\"RGB\")\n",
    "    plt.close()\n",
    "    return figimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplejson as json\n",
    "import numpy as np\n",
    "import numpy\n",
    "import math\n",
    "class StateEncoder(json.JSONEncoder):\n",
    "    \"\"\"\n",
    "    Source: Modified from stack overflow answer\n",
    "    \"\"\"\n",
    "    \n",
    "    def default(self, obj):\n",
    "        try:\n",
    "            if isinstance(obj, type):\n",
    "                return str(obj.__name__)\n",
    "            elif isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
    "                np.int16, np.int32, np.int64, np.uint8,\n",
    "                np.uint16, np.uint32, np.uint64)):\n",
    "                val = int(obj)\n",
    "                return val\n",
    "            elif isinstance(obj, (np.float_, np.float16, np.float32, \n",
    "                np.float64)):\n",
    "                val =  float(obj)\n",
    "                return val\n",
    "            elif isinstance(obj,(numpy.ndarray,)) or isinstance(obj,np.ndarray): #### This is the fix\n",
    "                return \"NOT SERIALIZED\" #json.JSONEncoder.default(self,{'size':obj.size,'shape':str(obj.shape),'status':\"NOT SERIALIZED\"})\n",
    "            else:\n",
    "                return json.JSONEncoder.default(self, obj)\n",
    "        except TypeError as te:\n",
    "            print(type(obj))\n",
    "            raise te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelinspector.vis_utils import get_concat_v_blank, resize_img, heatmap_legend, get_concat_h_blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps, ImageDraw\n",
    "image_border = (10,15,10,10)\n",
    "border_color = 'black'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([(0, 0)])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspector.graph_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HEATMAP\n",
    "def build_heatmaps(state_image_data,graph,state,data_group_types):\n",
    "    data_group_images = {}\n",
    "    min_width= 400\n",
    "    min_height = 40\n",
    "    img_created_counter = 0\n",
    "    for data_group_type,value_name in data_group_types:\n",
    "        node_images ={}\n",
    "        for nid,node in graph.nodes.items():\n",
    "            img = None\n",
    "            for cid in node['component_ids']:\n",
    "                component = graph.components[cid]\n",
    "                if component['data_group_type'] != data_group_type:\n",
    "                    continue\n",
    "                image_type = \"{}__image\".format(value_name)\n",
    "                component_state = state['data'][cid]\n",
    "\n",
    "                #We get our component image here, however we could generate it here instead (TODO)\n",
    "                cimg = state_image_data.get(cid,{}).get(image_type,None)\n",
    "                if cimg is not None:\n",
    "                    h = max(cimg.size[1],min_height) \n",
    "                    w = max(cimg.size[0],min_width) \n",
    "                    cimg = resize_img(cimg,w=w,min_h=h)\n",
    "\n",
    "                    cimg = ImageOps.expand(cimg, border=image_border,fill=border_color)\n",
    "                    draw = ImageDraw.Draw(cimg)\n",
    "                    draw.text((image_border[0], 0), \"{},{},{}, shape={}\".format(cid, value_name,image_type,component_state['shape']),(255, 255, 255))  # ,font=font))\n",
    "    # HEATMAP LEGEND, TODO              \n",
    "    #                 cstats = component_state['value'][\"{}__stats\".format(value_name)]\n",
    "    #                 legimg = heatmap_legend(cstats['min'],cstats['max'])\n",
    "    #                 cimg = get_concat_h_blank(cimg,legimg)\n",
    "                    if img is None:\n",
    "                        img = cimg\n",
    "                    else:\n",
    "                        img = get_concat_v_blank(img,cimg)\n",
    "            if img is not None:\n",
    "                node_images[nid] = img\n",
    "                img_created_counter +=1\n",
    "        data_group_images[(data_group_type,value_name)] = node_images\n",
    "    print(\"{} images created\".format(img_created_counter))\n",
    "    return data_group_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DIST FIGURES\n",
    "\n",
    "def build_dist_figures(graph,state):\n",
    "    data_group_dists = {}\n",
    "    img_created_counter = 0\n",
    "    for data_group_type,value_name in data_group_types:\n",
    "        node_images ={}\n",
    "        for nid,node in graph.nodes.items():\n",
    "            datasets=[]\n",
    "            for cid in node['component_ids']:\n",
    "                component = graph.components[cid]\n",
    "                if component['data_group_type'] != data_group_type:\n",
    "                    continue\n",
    "                component_state = state['data'][cid]\n",
    "                value = component_state['value'][value_name]\n",
    "                stats = component_state['value']['{}__stats'.format(value_name)]\n",
    "                datasets.append((\"{},{}\".format(cid,value_name),stats,value))\n",
    "            if len(datasets) >=1:\n",
    "                img = build_figs(datasets)\n",
    "                node_images[nid] = img\n",
    "                img_created_counter+=1\n",
    "        data_group_dists[(data_group_type,value_name)] = node_images\n",
    "    print(\"{} figure created\".format(img_created_counter))\n",
    "    return data_group_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save_node_images(group_images,image_type,output_path): #TODO: use these):\n",
    "    filenames = {}\n",
    "    os.makedirs(output_path,exist_ok=True)\n",
    "    for gid,node_images in group_images.items():\n",
    "        for nid, image_data in node_images.items():\n",
    "            filename = \"{}_{}_{}__{}.jpg\".format(nid,gid[0],gid[1],image_type)\n",
    "            image_data.save(os.path.join(output_path,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_root = 'graph_web/session_data/test/'\n",
    "\n",
    "!rm -rf {web_root}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 0_0\n",
      "104 images created\n",
      "104 figure created\n",
      "Saving 0_2\n",
      "104 images created\n",
      "104 figure created\n",
      "Saving 0_4\n",
      "104 images created\n",
      "104 figure created\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "data_group_types = [('PARAM','tensor'),('PARAM','grad'),('BUFFER','tensor'),('INPUT','tensor'),('OUTPUT','tensor')]\n",
    "session_data = {\n",
    "    'state_ids':[s['id'] for s in inspector.state_log[:3]]}\n",
    "\n",
    "os.makedirs(web_root,exist_ok=True);\n",
    "\n",
    "with open(os.path.join(web_root, \"session.json\"),'w') as f:\n",
    "    json.dump(session_data,f,cls=StateEncoder,ignore_nan=True)\n",
    "\n",
    "results = {}\n",
    "for state in  inspector.state_log[:3]:\n",
    "    print(\"Saving {}\".format(state['id']))\n",
    "\n",
    "    state_image_data = build_state_images(state)\n",
    "    graph = inspector.graph_data[state['graph_id']]\n",
    "    heatmap_images = build_heatmaps(state_image_data,graph,state,data_group_types)\n",
    "    dist_figures = build_dist_figures(graph,state)\n",
    "\n",
    "\n",
    "\n",
    "    graph_out = build_cyto_graph_file(graph)\n",
    "\n",
    "    #todo: save images to disk\n",
    "    state_path= os.path.join(web_root,state['id'])\n",
    "    image_path = os.path.join(state_path,\"images\")\n",
    "    os.makedirs(image_path,exist_ok=True);\n",
    "\n",
    "    #Saving images\n",
    "    save_node_images(heatmap_images,'heatmap',image_path)\n",
    "    save_node_images(dist_figures,'dist',image_path)\n",
    "    #save_images(state_image_data,image_path)\n",
    "\n",
    "    with open(os.path.join(state_path,\"graph.json\"),'w') as f:\n",
    "        json.dump(graph_out,f,cls=StateEncoder)\n",
    "\n",
    "    with open(os.path.join(state_path, \"state.json\"),'w') as f:\n",
    "        json.dump(state,f,cls=StateEncoder,ignore_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_figures[('PARAM', 'tensor')].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_figures[('PARAM', 'tensor')][191]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group_images.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_images[('PARAM', 'grad')][123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_images[('INPUT', 'tensor')]['input.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_images[('OUTPUT', 'tensor')]['output.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {}\n",
    "# for state in inspector.state_log:\n",
    "#     print(\"Saving {}\".format(state['id']))\n",
    "\n",
    "#     image_data,image_filenames = build_state_images(state,output_root=web_root)\n",
    "\n",
    "#     graph_out = build_cyto_graph_file(inspector.graph_data[state['graph_id']])\n",
    "#     state_path= os.path.join(web_root,state['id'])\n",
    "    \n",
    "#     save_images(image_data)\n",
    "\n",
    "#     with open(os.path.join(state_path,\"graph.json\"),'w') as f:\n",
    "#         json.dump(graph_out,f,cls=StateEncoder)\n",
    "\n",
    "#     with open(os.path.join(state_path, \"state.json\"),'w') as f:\n",
    "#         json.dump(state,f,cls=StateEncoder,ignore_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm  {state_path}/state.json\n",
    "\n",
    "# !ls -lstrh {state_path}/state.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat {state_path}/state.json | grep NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lstrh {state_path}/state.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlevo",
   "language": "python",
   "name": "rlevo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
