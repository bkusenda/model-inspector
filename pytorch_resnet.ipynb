{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/szagoruyko/pytorchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.3.1\n",
      "tensorboardX: 2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorboardX\n",
    "print(\"torch:\",torch.__version__)\n",
    "print(\"tensorboardX:\",tensorboardX.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "\n",
    "best_acc1 = 0\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if args.gpu is not None:\n",
    "                images = images.cuda(args.gpu, non_blocking=True)\n",
    "            target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, lr):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alexnet',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'googlenet',\n",
       " 'inception_v3',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet_v2',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext50_32x4d',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"~/image_net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~/image_net'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  val\r\n"
     ]
    }
   ],
   "source": [
    "!ls {data_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch='resnet18'\n",
    "lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'resnet18'\n"
     ]
    }
   ],
   "source": [
    "global best_acc1\n",
    "batch_size = 4\n",
    "# create model\n",
    "# if args.pretrained:\n",
    "#     print(\"=> using pre-trained model '{}'\".format(args.arch))\n",
    "#     model = models.__dict__[args.arch](pretrained=True)\n",
    "# else:\n",
    "print(\"=> creating model '{}'\".format(arch))\n",
    "model = models.__dict__[arch]()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr,\n",
    "                            momentum=0.9,\n",
    "                            weight_decay=1e-4)\n",
    "\n",
    "\n",
    "# Data loading code\n",
    "traindir = os.path.join(data_path, 'train')\n",
    "valdir = os.path.join(data_path, 'val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size,\n",
    "    num_workers=8)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=batch_size, shuffle=False,\n",
    "    num_workers=2)\n",
    "\n",
    "# if args.evaluate:\n",
    "#     validate(val_loader, model, criterion, args)\n",
    "# else:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelinspector.inspector import build_state_images, stats_suffix, DataGroupType_BUFFER, DataGroupType_INPUT, DataGroupType_LABEL, DataGroupType_OUTPUT, DataGroupType_PARAM, DataGroupType_LOSS\n",
    "from modelinspector.vis_utils import tensor_to_image, tensor_to_dist, fig2img\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelinspector.vis_utils import get_concat_v_blank, resize_img, heatmap_legend, get_concat_h_blank\n",
    "\n",
    "def make_image(v, \n",
    "               value_name, \n",
    "               use_color_for_3channel_data=False):\n",
    "    min_width = 400\n",
    "    min_height = 60\n",
    "    \n",
    "    stats_value_name = '{}{}'.format(value_name,stats_suffix)\n",
    "    \n",
    "    if value_name not in v or stats_value_name not in v:\n",
    "        return None\n",
    "    stats = v[stats_value_name]\n",
    "    \n",
    "    img = tensor_to_image(\n",
    "            val = v[value_name],\n",
    "            vstats = stats,\n",
    "            use_color_for_3channel_data = use_color_for_3channel_data)\n",
    "    \n",
    "    h = max(img.size[1],min_height) \n",
    "    w = max(img.size[0],min_width) \n",
    "    img = resize_img(img,w=w,min_h=h)\n",
    "#     Add HM legend\n",
    "    if not use_color_for_3channel_data:\n",
    "        legimg = heatmap_legend(stats['min'],stats['max'])\n",
    "        img = get_concat_h_blank(img,legimg)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_state_images(\n",
    "                state,\n",
    "                state_stats=None):\n",
    "    \n",
    "    state_image_data = {}\n",
    "    for group_name, group_data in state['data'].items():\n",
    "        image_data = {}\n",
    "        for value_name in ['tensor','grad','first_delta']:\n",
    "            \n",
    "            img = make_image(\n",
    "                    v = group_data['value'],\n",
    "                    value_name = value_name,\n",
    "                    use_color_for_3channel_data=group_data['data_group_type'] == DataGroupType_INPUT)\n",
    "            if img is not None:\n",
    "                image_data[\"{}__image\".format(value_name)] = img\n",
    "        state_image_data[group_name] = image_data\n",
    "        \n",
    "    return state_image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cyto_graph_file(graph):\n",
    "    nodes = []\n",
    "    edges = []\n",
    "    only_one_input = []\n",
    "    for nid,node in graph.nodes.items():\n",
    "        nodes.append({\"data\":{\"id\":nid,'label':node['op_type'],'component_ids':node['component_ids']}})\n",
    "\n",
    "    for eid,edge in graph.edges.items():\n",
    "        edges.append({'data':{'id':eid,\"source\":edge['source_id'],'target':edge['target_id']}})\n",
    "        \n",
    "    return {'nodes':nodes,'edges':edges}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplejson as json\n",
    "import numpy as np\n",
    "import numpy\n",
    "import math\n",
    "class StateEncoder(json.JSONEncoder):\n",
    "    \"\"\"\n",
    "    Source: Modified from stack overflow answer\n",
    "    \"\"\"\n",
    "    \n",
    "    def default(self, obj):\n",
    "        try:\n",
    "            if isinstance(obj, type):\n",
    "                return str(obj.__name__)\n",
    "            elif isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
    "                np.int16, np.int32, np.int64, np.uint8,\n",
    "                np.uint16, np.uint32, np.uint64)):\n",
    "                val = int(obj)\n",
    "                return val\n",
    "            elif isinstance(obj, (np.float_, np.float16, np.float32, \n",
    "                np.float64)):\n",
    "                val =  float(obj)\n",
    "                return val\n",
    "            elif isinstance(obj,(numpy.ndarray,)) or isinstance(obj,np.ndarray): #### This is the fix\n",
    "                if(obj.ndim == 1 and obj.size <=200):\n",
    "                    return obj.tolist()\n",
    "                else:\n",
    "                    return \"NOT SERIALIZED\" #json.JSONEncoder.default(self,{'size':obj.size,'shape':str(obj.shape),'status':\"NOT SERIALIZED\"})\n",
    "            else:\n",
    "                return json.JSONEncoder.default(self, obj)\n",
    "        except TypeError as te:\n",
    "            print(type(obj))\n",
    "            raise te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(state_image_data,output_path): #TODO: use these):\n",
    "    filenames = {}\n",
    "    os.makedirs(output_path,exist_ok=True)\n",
    "    for group_name, image_data in state_image_data.items():\n",
    "        filename_list = []\n",
    "        for img_name,img in image_data.items():\n",
    "            filename = \"{}_{}.jpg\".format(group_name,img_name)\n",
    "            filename_list.append({'filename':filename,'size': img.size})\n",
    "            img.save(os.path.join(output_path,filename))\n",
    "        state_image_data[group_name] = image_data\n",
    "        filenames[group_name] = filename_list\n",
    "        \n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_session(inspector,session_id,session_root):\n",
    "    session_data = {\n",
    "        'session_id': session_id,\n",
    "        'session_metrics': { v['id']:v for v in inspector.metrics_log},\n",
    "        'metric_ids':[s['id'] for s in inspector.metrics_log],\n",
    "        'state_ids':[s['id'] for s in inspector.state_log],\n",
    "         'component_stats':inspector.global_stats\n",
    "    }\n",
    "\n",
    "    os.makedirs(session_root,exist_ok=True);\n",
    "\n",
    "    with open(os.path.join(session_root, \"session.json\"),'w') as f:\n",
    "        json.dump(session_data,f,cls=StateEncoder,ignore_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_last_state(inspector,session_root):\n",
    "    state = inspector.state_log[-1]\n",
    "    print(\"Saving {}\".format(state['id']))\n",
    "\n",
    "    state_image_data = build_state_images(state)\n",
    "    graph = inspector.graph_data[state['graph_id']]\n",
    "    \n",
    "    graph_out = build_cyto_graph_file(graph)\n",
    "    state['graph'] = graph_out\n",
    "    \n",
    "    # Paths\n",
    "    state_path= os.path.join(session_root,state['id'])\n",
    "    image_path = os.path.join(state_path,\"images\")\n",
    "    os.makedirs(image_path,exist_ok=True);\n",
    "    save_images(state_image_data,image_path)\n",
    "\n",
    "    with open(os.path.join(state_path, \"state.json\"),'w') as f:\n",
    "        print(state_path)\n",
    "        print(state.keys())\n",
    "        json.dump(state,f,cls=StateEncoder,ignore_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURE\n",
    "data_root = 'graph_web/session_data'\n",
    "session_id = \"test7\"\n",
    "session_root = os.path.join(data_root,session_id)\n",
    "os.makedirs(session_root,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {session_root}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelinspector.inspector import Inspector\n",
    "inspector = Inspector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing graph (0, 0)..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brandyn/anaconda3/envs/rlevo/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3506: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "/home/brandyn/anaconda3/envs/rlevo/lib/python3.7/site-packages/numpy/core/_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/brandyn/anaconda3/envs/rlevo/lib/python3.7/site-packages/numpy/core/_methods.py:209: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 0_0\n",
      "graph_web/session_data/test7/0_0\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][   0/4852]\tTime  0.000 ( 0.000)\tData  0.351 ( 0.351)\tLoss 6.9990e+00 (6.9990e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Saving 0_1000\n",
      "graph_web/session_data/test7/0_1000\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][1000/4852]\tTime  0.019 ( 0.027)\tData  0.002 ( 0.002)\tLoss 7.9070e+00 (7.5817e+00)\tAcc@1   0.00 (  1.00)\tAcc@5   0.00 (  3.97)\n",
      "Saving 0_2000\n",
      "graph_web/session_data/test7/0_2000\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][2000/4852]\tTime  0.017 ( 0.027)\tData  0.001 ( 0.002)\tLoss 7.9069e+00 (7.6247e+00)\tAcc@1   0.00 (  0.50)\tAcc@5   0.00 (  1.99)\n",
      "Saving 0_3000\n",
      "graph_web/session_data/test7/0_3000\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][3000/4852]\tTime  0.017 ( 0.027)\tData  0.001 ( 0.002)\tLoss 8.4995e+00 (7.6917e+00)\tAcc@1   0.00 (  0.33)\tAcc@5   0.00 (  1.32)\n"
     ]
    }
   ],
   "source": [
    "state_log_freq = 1000\n",
    "metric_log_freq = 50\n",
    "\n",
    "for epoch in range(0, 5000):\n",
    "        adjust_learning_rate(optimizer, epoch, lr)\n",
    "\n",
    "        # train for one epoch\n",
    "#         train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "#         for it in sdf:\n",
    "        batch_time = AverageMeter('Time', ':6.3f')\n",
    "        data_time = AverageMeter('Data', ':6.3f')\n",
    "        losses = AverageMeter('Loss', ':.4e')\n",
    "        top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "        top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "        progress = ProgressMeter(\n",
    "            len(train_loader),\n",
    "            [batch_time, data_time, losses, top1, top5],\n",
    "            prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "        # switch to train mode\n",
    "        model.train()\n",
    "\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(train_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # compute gradient and do SGD step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            try:\n",
    "\n",
    "                if i % state_log_freq == 0:\n",
    "                    inspector.log_state(epoch=epoch,\n",
    "                              itr=i, \n",
    "                              model=model,\n",
    "                              input_dict={'input.1':images},\n",
    "                              output_dict={'output.1':output},\n",
    "                              loss_dict={'loss':loss},\n",
    "                              label_dict={'class_label':target})\n",
    "                    inspector.compute_stats()\n",
    "                    save_last_state(inspector,session_root)\n",
    "                    progress.display(i)\n",
    "\n",
    "\n",
    "                if i % metric_log_freq == 0 or i % state_log_freq == 0:\n",
    "                    inspector.log_metrics(\n",
    "                        epoch=epoch,\n",
    "                        itr=i, \n",
    "                        metrics={\n",
    "                            'loss':loss.item(),\n",
    "                            'acc1':acc1[0].item(),\n",
    "                            'acc5':acc5[0].item()})\n",
    "\n",
    "                    save_session(inspector,session_id,session_root)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                        \n",
    "            optimizer.step()\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            \n",
    "        # evaluate on validation set\n",
    "        #acc1 = validate(val_loader, model, criterion, args)\n",
    "\n",
    "        # remember best acc@1 and save checkpoint\n",
    "        #is_best = acc1 > best_acc1\n",
    "        #best_acc1 = max(acc1, best_acc1)\n",
    "        \n",
    "# ON CPU\n",
    "# Computing graph (0, 0)..\n",
    "# Computing graph (0, 0)..\n",
    "# Epoch: [0][   0/4852]\tTime  1.260 ( 1.260)\tData  0.072 ( 0.072)\tLoss 6.6802e+00 (6.6802e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
    "# Epoch: [0][ 200/4852]\tTime  0.593 ( 0.675)\tData  0.002 ( 0.002)\tLoss 7.8017e+00 (9.1996e+00)\tAcc@1   0.00 (  5.10)\tAcc@5   0.00 ( 19.78)\n",
    "# Epoch: [1][   0/4852]\tTime  0.864 ( 0.864)\tData  0.155 ( 0.155)\tLoss 9.2710e+00 (9.2710e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
    "# Epoch: [1][ 200/4852]\tTime  0.706 ( 0.599)\tData  0.002 ( 0.002)\tLoss 6.3036e+00 (5.9345e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_session(inspector,session_id,session_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from modelinspector.vis_utils import get_concat_v_blank, resize_img, heatmap_legend, get_concat_h_blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib agg\n",
    "# import matplotlib.pyplot as plt\n",
    "# #datasets = [('name',{'xmin':-10,'xmax':30},dd) for x in range(0,5)]\n",
    "# def build_figs(datasets,n_bins=40):\n",
    "#     fig, axs = plt.subplots(len(datasets), 1, tight_layout=True,figsize=(8,8));\n",
    "\n",
    "#     for i,(name,stats,data) in enumerate(datasets):\n",
    "#         if len(datasets)==1:\n",
    "#             ax = axs\n",
    "#         else:\n",
    "#             ax = axs[i]\n",
    "\n",
    "#         if data.ndim >1:\n",
    "#             data = data.ravel()\n",
    "\n",
    "#         bins = min(int(data.size/10)+2, n_bins)\n",
    "\n",
    "#         ax.hist(data, bins=bins,range=(stats['min'],stats['max']))\n",
    "#         ax.set_title(name)\n",
    "\n",
    "#     figimg = fig2img(fig).convert(\"RGB\")\n",
    "#     plt.close()\n",
    "#     return figimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## HEATMAP\n",
    "# from PIL import Image, ImageOps, ImageDraw\n",
    "# image_border = (10,15,10,10)\n",
    "# border_color = 'black'\n",
    "\n",
    "# def build_heatmaps(state_image_data,graph,state,data_group_types):\n",
    "#     data_group_images = {}\n",
    "#     min_width= 400\n",
    "#     min_height = 40\n",
    "#     img_created_counter = 0\n",
    "#     for data_group_type,value_name in data_group_types:\n",
    "#         node_images ={}\n",
    "#         for nid,node in graph.nodes.items():\n",
    "#             img = None\n",
    "#             for cid in node['component_ids']:\n",
    "#                 component = graph.components[cid]\n",
    "#                 if component['data_group_type'] != data_group_type:\n",
    "#                     continue\n",
    "#                 image_type = \"{}__image\".format(value_name)\n",
    "#                 component_state = state['data'][cid]\n",
    "\n",
    "#                 #We get our component image here, however we could generate it here instead (TODO)\n",
    "#                 cimg = state_image_data.get(cid,{}).get(image_type,None)\n",
    "#                 if cimg is not None:\n",
    "#                     h = max(cimg.size[1],min_height) \n",
    "#                     w = max(cimg.size[0],min_width) \n",
    "#                     cimg = resize_img(cimg,w=w,min_h=h)\n",
    "\n",
    "#                     cimg = ImageOps.expand(cimg, border=image_border,fill=border_color)\n",
    "#                     draw = ImageDraw.Draw(cimg)\n",
    "#                     draw.text((image_border[0], 0), \"{},{},{}, shape={}\".format(cid, value_name,image_type,component_state['shape']),(255, 255, 255))  # ,font=font))\n",
    "#     # HEATMAP LEGEND, TODO              \n",
    "#     #                 cstats = component_state['value'][\"{}__stats\".format(value_name)]\n",
    "#     #                 legimg = heatmap_legend(cstats['min'],cstats['max'])\n",
    "#     #                 cimg = get_concat_h_blank(cimg,legimg)\n",
    "#                     if img is None:\n",
    "#                         img = cimg\n",
    "#                     else:\n",
    "#                         img = get_concat_v_blank(img,cimg)\n",
    "#             if img is not None:\n",
    "#                 node_images[nid] = img\n",
    "#                 img_created_counter +=1\n",
    "#         data_group_images[(data_group_type,value_name)] = node_images\n",
    "#     print(\"{} images created\".format(img_created_counter))\n",
    "#     return data_group_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DIST FIGURES\n",
    "# def build_dist_figures(graph,state):\n",
    "#     data_group_dists = {}\n",
    "#     img_created_counter = 0\n",
    "#     for data_group_type,value_name in data_group_types:\n",
    "#         node_images ={}\n",
    "#         for nid,node in graph.nodes.items():\n",
    "#             datasets=[]\n",
    "#             for cid in node['component_ids']:\n",
    "#                 component = graph.components[cid]\n",
    "#                 if component['data_group_type'] != data_group_type:\n",
    "#                     continue\n",
    "#                 component_state = state['data'][cid]\n",
    "#                 value = component_state['value'][value_name]\n",
    "#                 stats = component_state['value']['{}__stats'.format(value_name)]\n",
    "#                 datasets.append((\"{},{}\".format(cid,value_name),stats,value))\n",
    "#             if len(datasets) >=1:\n",
    "#                 img = build_figs(datasets)\n",
    "#                 node_images[nid] = img\n",
    "#                 img_created_counter+=1\n",
    "#         data_group_dists[(data_group_type,value_name)] = node_images\n",
    "#     print(\"{} figure created\".format(img_created_counter))\n",
    "#     return data_group_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_out['nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lstrh {state_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# def save_node_images(group_images,image_type,output_path): #TODO: use these):\n",
    "#     filenames = {}\n",
    "#     os.makedirs(output_path,exist_ok=True)\n",
    "#     for gid,node_images in group_images.items():\n",
    "#         nfilenames = {}\n",
    "#         for nid, image_data in node_images.items():\n",
    "#             filename = \"{}_{}_{}__{}.jpg\".format(nid,gid[0],gid[1],image_type)\n",
    "#             image_data.save(os.path.join(output_path,filename))\n",
    "#             nfilenames[nid] = filename\n",
    "#         filenames[gid] = nfilenames\n",
    "#     return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['graph']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlevo",
   "language": "python",
   "name": "rlevo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
