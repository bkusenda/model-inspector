{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/szagoruyko/pytorchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.3.1\n",
      "tensorboardX: 2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorboardX\n",
    "print(\"torch:\",torch.__version__)\n",
    "print(\"tensorboardX:\",tensorboardX.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "\n",
    "best_acc1 = 0\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if args.gpu is not None:\n",
    "                images = images.cuda(args.gpu, non_blocking=True)\n",
    "            target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, lr):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alexnet',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'googlenet',\n",
       " 'inception_v3',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet_v2',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext50_32x4d',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"~/image_net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~/image_net'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  val\r\n"
     ]
    }
   ],
   "source": [
    "!ls {data_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch='resnet18'\n",
    "lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'resnet18'\n"
     ]
    }
   ],
   "source": [
    "global best_acc1\n",
    "batch_size = 4\n",
    "# create model\n",
    "# if args.pretrained:\n",
    "#     print(\"=> using pre-trained model '{}'\".format(args.arch))\n",
    "#     model = models.__dict__[args.arch](pretrained=True)\n",
    "# else:\n",
    "print(\"=> creating model '{}'\".format(arch))\n",
    "model = models.__dict__[arch]()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr,\n",
    "                            momentum=0.9,\n",
    "                            weight_decay=1e-4)\n",
    "\n",
    "\n",
    "# Data loading code\n",
    "traindir = os.path.join(data_path, 'train')\n",
    "valdir = os.path.join(data_path, 'val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size,\n",
    "    num_workers=8)\n",
    "\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     datasets.ImageFolder(valdir, transforms.Compose([\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         normalize,\n",
    "#     ])),\n",
    "#     batch_size=batch_size, shuffle=False,\n",
    "#     num_workers=2)\n",
    "\n",
    "# if args.evaluate:\n",
    "#     validate(val_loader, model, criterion, args)\n",
    "# else:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURE\n",
    "data_root = 'graph_web/session_data'\n",
    "session_id = \"test10\"\n",
    "\n",
    "from modelinspector.inspector import Inspector\n",
    "inspector = Inspector(session_id,data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "itr_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing graph (0, 0)..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brandyn/anaconda3/envs/rlevo/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3506: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "/home/brandyn/anaconda3/envs/rlevo/lib/python3.7/site-packages/numpy/core/_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/brandyn/anaconda3/envs/rlevo/lib/python3.7/site-packages/numpy/core/_methods.py:209: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 0_0\n",
      "graph_web/session_data/test10/0_0\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][   0/4852]\tTime  0.000 ( 0.000)\tData  0.190 ( 0.190)\tLoss 6.8029e+00 (6.8029e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Saving 0_13\n",
      "graph_web/session_data/test10/0_13\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][  13/4852]\tTime  0.045 ( 0.557)\tData  0.001 ( 0.016)\tLoss 4.4524e+01 (2.0677e+01)\tAcc@1  50.00 ( 69.64)\tAcc@5  50.00 ( 83.93)\n",
      "Saving 0_26\n",
      "graph_web/session_data/test10/0_26\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][  26/4852]\tTime  0.022 ( 0.526)\tData  0.002 ( 0.009)\tLoss 7.0041e+00 (1.8518e+01)\tAcc@1   0.00 ( 38.89)\tAcc@5   0.00 ( 86.11)\n",
      "Saving 0_39\n",
      "graph_web/session_data/test10/0_39\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][  39/4852]\tTime  0.031 ( 0.511)\tData  0.003 ( 0.007)\tLoss 5.9659e+00 (1.4570e+01)\tAcc@1   0.00 ( 26.25)\tAcc@5  75.00 ( 88.12)\n",
      "Saving 0_52\n",
      "graph_web/session_data/test10/0_52\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][  52/4852]\tTime  0.033 ( 0.504)\tData  0.001 ( 0.005)\tLoss 7.0572e+00 (1.2711e+01)\tAcc@1   0.00 ( 19.81)\tAcc@5   0.00 ( 75.00)\n",
      "Saving 0_65\n",
      "graph_web/session_data/test10/0_65\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][  65/4852]\tTime  0.039 ( 0.506)\tData  0.002 ( 0.005)\tLoss 6.6391e+00 (1.1567e+01)\tAcc@1   0.00 ( 15.91)\tAcc@5   0.00 ( 60.23)\n",
      "Saving 0_78\n",
      "graph_web/session_data/test10/0_78\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][  78/4852]\tTime  0.025 ( 0.501)\tData  0.001 ( 0.004)\tLoss 6.3945e+00 (1.0758e+01)\tAcc@1   0.00 ( 13.29)\tAcc@5   0.00 ( 50.32)\n",
      "Saving 0_91\n",
      "graph_web/session_data/test10/0_91\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][  91/4852]\tTime  0.031 ( 0.500)\tData  0.002 ( 0.004)\tLoss 6.6719e+00 (1.0227e+01)\tAcc@1   0.00 ( 11.41)\tAcc@5   0.00 ( 43.21)\n",
      "Saving 0_104\n",
      "graph_web/session_data/test10/0_104\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 104/4852]\tTime  0.028 ( 0.498)\tData  0.002 ( 0.004)\tLoss 7.5085e+00 (9.8380e+00)\tAcc@1   0.00 ( 10.00)\tAcc@5   0.00 ( 37.86)\n",
      "Saving 0_117\n",
      "graph_web/session_data/test10/0_117\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 117/4852]\tTime  0.029 ( 0.496)\tData  0.002 ( 0.003)\tLoss 6.3928e+00 (9.5009e+00)\tAcc@1   0.00 (  8.90)\tAcc@5   0.00 ( 33.69)\n",
      "Saving 0_130\n",
      "graph_web/session_data/test10/0_130\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 130/4852]\tTime  0.025 ( 0.497)\tData  0.003 ( 0.003)\tLoss 6.6568e+00 (9.2510e+00)\tAcc@1   0.00 (  8.02)\tAcc@5   0.00 ( 30.34)\n",
      "Saving 0_143\n",
      "graph_web/session_data/test10/0_143\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 143/4852]\tTime  0.040 ( 0.496)\tData  0.003 ( 0.003)\tLoss 7.7075e+00 (9.0676e+00)\tAcc@1   0.00 (  7.29)\tAcc@5   0.00 ( 27.60)\n",
      "Saving 0_156\n",
      "graph_web/session_data/test10/0_156\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 156/4852]\tTime  0.035 ( 0.495)\tData  0.001 ( 0.003)\tLoss 7.7262e+00 (8.9043e+00)\tAcc@1   0.00 (  6.69)\tAcc@5   0.00 ( 25.32)\n",
      "Saving 0_169\n",
      "graph_web/session_data/test10/0_169\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 169/4852]\tTime  0.029 ( 0.494)\tData  0.002 ( 0.003)\tLoss 5.6547e+00 (8.7503e+00)\tAcc@1   0.00 (  6.18)\tAcc@5   0.00 ( 23.38)\n",
      "Saving 0_182\n",
      "graph_web/session_data/test10/0_182\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 182/4852]\tTime  0.035 ( 0.493)\tData  0.002 ( 0.003)\tLoss 6.5474e+00 (8.6343e+00)\tAcc@1   0.00 (  5.74)\tAcc@5   0.00 ( 21.72)\n",
      "Saving 0_195\n",
      "graph_web/session_data/test10/0_195\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 195/4852]\tTime  0.034 ( 0.497)\tData  0.002 ( 0.003)\tLoss 7.8010e+00 (8.5490e+00)\tAcc@1   0.00 (  5.36)\tAcc@5   0.00 ( 20.28)\n",
      "Saving 0_208\n",
      "graph_web/session_data/test10/0_208\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 208/4852]\tTime  0.029 ( 0.497)\tData  0.002 ( 0.003)\tLoss 7.4314e+00 (8.4729e+00)\tAcc@1   0.00 (  5.02)\tAcc@5   0.00 ( 19.02)\n",
      "Saving 0_221\n",
      "graph_web/session_data/test10/0_221\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 221/4852]\tTime  0.032 ( 0.496)\tData  0.002 ( 0.003)\tLoss 6.7099e+00 (8.3960e+00)\tAcc@1   0.00 (  4.73)\tAcc@5   0.00 ( 17.91)\n",
      "Saving 0_234\n",
      "graph_web/session_data/test10/0_234\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 234/4852]\tTime  0.033 ( 0.496)\tData  0.001 ( 0.003)\tLoss 5.5892e+00 (8.3175e+00)\tAcc@1   0.00 (  4.47)\tAcc@5   0.00 ( 16.91)\n",
      "Saving 0_247\n",
      "graph_web/session_data/test10/0_247\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 247/4852]\tTime  0.038 ( 0.495)\tData  0.006 ( 0.003)\tLoss 7.7940e+00 (8.2313e+00)\tAcc@1   0.00 (  4.23)\tAcc@5   0.00 ( 16.03)\n",
      "Saving 0_260\n",
      "graph_web/session_data/test10/0_260\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 260/4852]\tTime  0.026 ( 0.495)\tData  0.002 ( 0.003)\tLoss 8.2294e+00 (8.1875e+00)\tAcc@1   0.00 (  4.02)\tAcc@5   0.00 ( 15.23)\n",
      "Saving 0_273\n",
      "graph_web/session_data/test10/0_273\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 273/4852]\tTime  0.054 ( 0.495)\tData  0.002 ( 0.003)\tLoss 7.7971e+00 (8.1540e+00)\tAcc@1   0.00 (  3.83)\tAcc@5   0.00 ( 14.51)\n",
      "Saving 0_286\n",
      "graph_web/session_data/test10/0_286\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 286/4852]\tTime  0.027 ( 0.495)\tData  0.002 ( 0.003)\tLoss 7.8371e+00 (8.1072e+00)\tAcc@1   0.00 (  3.66)\tAcc@5   0.00 ( 13.85)\n",
      "Saving 0_299\n",
      "graph_web/session_data/test10/0_299\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 299/4852]\tTime  0.040 ( 0.495)\tData  0.002 ( 0.002)\tLoss 7.9111e+00 (8.0685e+00)\tAcc@1   0.00 (  3.50)\tAcc@5   0.00 ( 13.25)\n",
      "Saving 0_312\n",
      "graph_web/session_data/test10/0_312\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 312/4852]\tTime  0.026 ( 0.496)\tData  0.006 ( 0.002)\tLoss 7.7756e+00 (8.0425e+00)\tAcc@1   0.00 (  3.35)\tAcc@5   0.00 ( 12.70)\n",
      "Saving 0_325\n",
      "graph_web/session_data/test10/0_325\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 325/4852]\tTime  0.040 ( 0.495)\tData  0.003 ( 0.002)\tLoss 7.3405e+00 (8.0162e+00)\tAcc@1   0.00 (  3.22)\tAcc@5   0.00 ( 12.19)\n",
      "Saving 0_338\n",
      "graph_web/session_data/test10/0_338\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 338/4852]\tTime  0.026 ( 0.495)\tData  0.002 ( 0.002)\tLoss 6.3905e+00 (7.9847e+00)\tAcc@1   0.00 (  3.10)\tAcc@5   0.00 ( 11.73)\n",
      "Saving 0_351\n",
      "graph_web/session_data/test10/0_351\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 351/4852]\tTime  0.080 ( 0.495)\tData  0.004 ( 0.002)\tLoss 7.8569e+00 (7.9623e+00)\tAcc@1   0.00 (  2.98)\tAcc@5   0.00 ( 11.29)\n",
      "Saving 0_364\n",
      "graph_web/session_data/test10/0_364\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 364/4852]\tTime  0.050 ( 0.495)\tData  0.002 ( 0.002)\tLoss 7.0885e+00 (7.9448e+00)\tAcc@1   0.00 (  2.88)\tAcc@5   0.00 ( 10.89)\n",
      "Saving 0_377\n",
      "graph_web/session_data/test10/0_377\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 377/4852]\tTime  0.028 ( 0.495)\tData  0.001 ( 0.002)\tLoss 7.6521e+00 (7.9108e+00)\tAcc@1   0.00 (  2.78)\tAcc@5   0.00 ( 10.52)\n",
      "Saving 0_390\n",
      "graph_web/session_data/test10/0_390\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 390/4852]\tTime  0.029 ( 0.495)\tData  0.002 ( 0.002)\tLoss 6.5154e+00 (7.8798e+00)\tAcc@1   0.00 (  2.69)\tAcc@5   0.00 ( 10.17)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 0_403\n",
      "graph_web/session_data/test10/0_403\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 403/4852]\tTime  0.069 ( 0.495)\tData  0.002 ( 0.002)\tLoss 6.7980e+00 (7.8610e+00)\tAcc@1   0.00 (  2.60)\tAcc@5   0.00 (  9.84)\n",
      "Saving 0_416\n",
      "graph_web/session_data/test10/0_416\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 416/4852]\tTime  0.041 ( 0.495)\tData  0.001 ( 0.002)\tLoss 6.8442e+00 (7.8486e+00)\tAcc@1   0.00 (  2.52)\tAcc@5   0.00 (  9.53)\n",
      "Saving 0_429\n",
      "graph_web/session_data/test10/0_429\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 429/4852]\tTime  0.065 ( 0.495)\tData  0.002 ( 0.002)\tLoss 7.0236e+00 (7.8355e+00)\tAcc@1   0.00 (  2.44)\tAcc@5   0.00 (  9.24)\n",
      "Saving 0_442\n",
      "graph_web/session_data/test10/0_442\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 442/4852]\tTime  0.050 ( 0.496)\tData  0.002 ( 0.002)\tLoss 7.9285e+00 (7.8106e+00)\tAcc@1   0.00 (  2.37)\tAcc@5   0.00 (  8.97)\n",
      "Saving 0_455\n",
      "graph_web/session_data/test10/0_455\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 455/4852]\tTime  0.043 ( 0.496)\tData  0.002 ( 0.002)\tLoss 7.8821e+00 (7.8056e+00)\tAcc@1   0.00 (  2.30)\tAcc@5   0.00 (  8.72)\n",
      "Saving 0_468\n",
      "graph_web/session_data/test10/0_468\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 468/4852]\tTime  0.029 ( 0.496)\tData  0.002 ( 0.002)\tLoss 7.4573e+00 (7.7988e+00)\tAcc@1   0.00 (  2.24)\tAcc@5   0.00 (  8.48)\n",
      "Saving 0_481\n",
      "graph_web/session_data/test10/0_481\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 481/4852]\tTime  0.042 ( 0.496)\tData  0.002 ( 0.002)\tLoss 7.9399e+00 (7.7793e+00)\tAcc@1   0.00 (  2.18)\tAcc@5   0.00 (  8.25)\n",
      "Saving 0_494\n",
      "graph_web/session_data/test10/0_494\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 494/4852]\tTime  0.095 ( 0.496)\tData  0.007 ( 0.002)\tLoss 7.6084e+00 (7.7754e+00)\tAcc@1   0.00 (  2.12)\tAcc@5   0.00 (  8.03)\n",
      "Saving 0_507\n",
      "graph_web/session_data/test10/0_507\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 507/4852]\tTime  0.045 ( 0.496)\tData  0.002 ( 0.002)\tLoss 7.1004e+00 (7.7653e+00)\tAcc@1   0.00 (  2.07)\tAcc@5   0.00 (  7.82)\n",
      "Saving 0_520\n",
      "graph_web/session_data/test10/0_520\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 520/4852]\tTime  0.018 ( 0.496)\tData  0.001 ( 0.002)\tLoss 6.9988e+00 (7.7546e+00)\tAcc@1   0.00 (  2.02)\tAcc@5   0.00 (  7.63)\n",
      "Saving 0_533\n",
      "graph_web/session_data/test10/0_533\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 533/4852]\tTime  0.048 ( 0.496)\tData  0.002 ( 0.002)\tLoss 7.9908e+00 (7.7475e+00)\tAcc@1   0.00 (  1.97)\tAcc@5   0.00 (  7.44)\n",
      "Saving 0_546\n",
      "graph_web/session_data/test10/0_546\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 546/4852]\tTime  0.023 ( 0.498)\tData  0.001 ( 0.002)\tLoss 7.6600e+00 (7.7358e+00)\tAcc@1   0.00 (  1.92)\tAcc@5   0.00 (  7.27)\n",
      "Saving 0_559\n",
      "graph_web/session_data/test10/0_559\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 559/4852]\tTime  0.080 ( 0.498)\tData  0.002 ( 0.002)\tLoss 7.2823e+00 (7.7272e+00)\tAcc@1   0.00 (  1.88)\tAcc@5   0.00 (  7.10)\n",
      "Saving 0_572\n",
      "graph_web/session_data/test10/0_572\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 572/4852]\tTime  0.039 ( 0.498)\tData  0.005 ( 0.002)\tLoss 6.1471e+00 (7.7185e+00)\tAcc@1   0.00 (  1.83)\tAcc@5   0.00 (  6.94)\n",
      "Saving 0_585\n",
      "graph_web/session_data/test10/0_585\n",
      "dict_keys(['id', 'meta', 'step_info', 'additional_info', 'graph_id', 'data', 'graph'])\n",
      "Epoch: [0][ 585/4852]\tTime  0.054 ( 0.498)\tData  0.002 ( 0.002)\tLoss 6.4171e+00 (7.7113e+00)\tAcc@1   0.00 (  1.79)\tAcc@5   0.00 (  6.78)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2e9c60ac92b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m                               \u001b[0moutput_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'output.1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                               \u001b[0mloss_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                               label_dict={'class_label':target})\n\u001b[0m\u001b[1;32m     53\u001b[0m                     \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/workspace_playground/modelinspector/inspector.py\u001b[0m in \u001b[0;36mlog_state\u001b[0;34m(self, epoch, itr, model, input_dict, output_dict, label_dict, loss_dict, refresh_model_graph, additional_info)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_param_deltas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_stats_for_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;31m#self.state_stats.append(stats)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/workspace_playground/modelinspector/inspector.py\u001b[0m in \u001b[0;36mcompute_stats_for_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    348\u001b[0m                     \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nobs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                     \u001b[0mstats_updated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'histogram_bins'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                     \u001b[0mstats_updated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'histogram'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m                     \u001b[0mstats_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"{}{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstats_suffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats_updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlevo/lib/python3.7/site-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0mf_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unsigned_subtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_edge\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_equal_bins\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0;31m# The index computation is not guaranteed to give exactly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state_log_freq = 13\n",
    "metric_log_freq = 2\n",
    "\n",
    "while epoch < 2:\n",
    "        adjust_learning_rate(optimizer, epoch, lr)\n",
    "        batch_time = AverageMeter('Time', ':6.3f')\n",
    "        data_time = AverageMeter('Data', ':6.3f')\n",
    "        losses = AverageMeter('Loss', ':.4e')\n",
    "        top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "        top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "        progress = ProgressMeter(\n",
    "            len(train_loader),\n",
    "            [batch_time, data_time, losses, top1, top5],\n",
    "            prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "        # switch to train mode\n",
    "        model.train()\n",
    "\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(train_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # compute gradient and do SGD step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            try:\n",
    "\n",
    "                if i % state_log_freq == 0:\n",
    "                    inspector.log_state(epoch=epoch,\n",
    "                              itr=i, \n",
    "                              model=model,\n",
    "                              input_dict={'input.1':images},\n",
    "                              output_dict={'output.1':output},\n",
    "                              loss_dict={'loss':loss},\n",
    "                              label_dict={'class_label':target})\n",
    "                    progress.display(i)\n",
    "\n",
    "\n",
    "                if i % metric_log_freq == 0 or i % state_log_freq == 0:\n",
    "                    inspector.log_metrics(\n",
    "                        epoch=epoch,\n",
    "                        itr=i, \n",
    "                        metrics={\n",
    "                            'loss':loss.item(),\n",
    "                            'acc1':acc1[0].item(),\n",
    "                            'acc5':acc5[0].item()})\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                        \n",
    "            optimizer.step()\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            itr_total +=1\n",
    "        epoch+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_last_state(inspector,session_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspector.log_state(epoch=epoch,\n",
    "          itr=i, \n",
    "          model=model,\n",
    "          input_dict={'input.1':images},\n",
    "          output_dict={'output.1':output},\n",
    "          loss_dict={'loss':loss},\n",
    "          label_dict={'class_label':target})\n",
    "inspector.compute_stats()\n",
    "save_last_state(inspector,session_root)\n",
    "progress.display(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lstrh {state_path}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlevo",
   "language": "python",
   "name": "rlevo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
